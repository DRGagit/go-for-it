<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>6 See one, do one, teach one! Machine Learning in R | DRG/AGIT - Go for IT</title>
  <meta name="description" content="Dies ist das Begleitbuch für die Webinarreihe ‘Go for IT’." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="6 See one, do one, teach one! Machine Learning in R | DRG/AGIT - Go for IT" />
  <meta property="og:type" content="book" />
  
  <meta property="og:image" content="./assets/img/banner.png" />
  <meta property="og:description" content="Dies ist das Begleitbuch für die Webinarreihe ‘Go for IT’." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="6 See one, do one, teach one! Machine Learning in R | DRG/AGIT - Go for IT" />
  
  <meta name="twitter:description" content="Dies ist das Begleitbuch für die Webinarreihe ‘Go for IT’." />
  <meta name="twitter:image" content="./assets/img/banner.png" />

<meta name="author" content="Bettina Baeßler &amp; Daniel Pinto dos Santos" />


<meta name="date" content="2020-12-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="diverse-tipps-tricks-für-r.html"/>
<link rel="next" href="bilddaten-datenbilder-radiomics-analysen-in-r.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-119151357-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-119151357-2');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">DRG/AGIT - Go for IT</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Einleitung</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#termine-der-live-webinare-20192020"><i class="fa fa-check"></i>Termine der Live-Webinare 2019/2020</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#zum-nachschauen"><i class="fa fa-check"></i>Zum Nachschauen</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html"><i class="fa fa-check"></i><b>1</b> Einstieg in R: erste Schritte</a>
<ul>
<li class="chapter" data-level="1.1" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#lernziele"><i class="fa fa-check"></i><b>1.1</b> Lernziele</a></li>
<li class="chapter" data-level="1.2" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#installation-von-r-und-rstudio"><i class="fa fa-check"></i><b>1.2</b> Installation von R und RStudio</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#installation-r"><i class="fa fa-check"></i><b>1.2.1</b> Installation R</a></li>
<li class="chapter" data-level="1.2.2" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#installation-rstudio"><i class="fa fa-check"></i><b>1.2.2</b> Installation RStudio</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#die-rstudio-oberfläche"><i class="fa fa-check"></i><b>1.3</b> Die RStudio Oberfläche</a></li>
<li class="chapter" data-level="1.4" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#arithmetische-operatoren"><i class="fa fa-check"></i><b>1.4</b> Arithmetische Operatoren</a></li>
<li class="chapter" data-level="1.5" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#logische-operatoren"><i class="fa fa-check"></i><b>1.5</b> Logische Operatoren</a></li>
<li class="chapter" data-level="1.6" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#besondere-operatoren"><i class="fa fa-check"></i><b>1.6</b> Besondere Operatoren</a></li>
<li class="chapter" data-level="1.7" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#variablen"><i class="fa fa-check"></i><b>1.7</b> Variablen</a></li>
<li class="chapter" data-level="1.8" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#funktionen"><i class="fa fa-check"></i><b>1.8</b> Funktionen</a></li>
<li class="chapter" data-level="1.9" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#vektoren"><i class="fa fa-check"></i><b>1.9</b> Vektoren</a></li>
<li class="chapter" data-level="1.10" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#dataframes"><i class="fa fa-check"></i><b>1.10</b> Dataframes</a></li>
<li class="chapter" data-level="1.11" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#daten-einlesen"><i class="fa fa-check"></i><b>1.11</b> Daten einlesen</a></li>
<li class="chapter" data-level="1.12" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#ausblick"><i class="fa fa-check"></i><b>1.12</b> Ausblick</a></li>
<li class="chapter" data-level="1.13" data-path="einstieg-in-r-erste-schritte.html"><a href="einstieg-in-r-erste-schritte.html#schlussbemerkungen"><i class="fa fa-check"></i><b>1.13</b> Schlussbemerkungen</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><a href="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><i class="fa fa-check"></i><b>2</b> Nächste Schritte in R: bunte Bilder und mehr</a>
<ul>
<li class="chapter" data-level="2.1" data-path="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><a href="nächste-schritte-in-r-bunte-bilder-und-mehr.html#lernziele-1"><i class="fa fa-check"></i><b>2.1</b> Lernziele</a></li>
<li class="chapter" data-level="2.2" data-path="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><a href="nächste-schritte-in-r-bunte-bilder-und-mehr.html#grafiken-in-base-r"><i class="fa fa-check"></i><b>2.2</b> Grafiken in Base R</a></li>
<li class="chapter" data-level="2.3" data-path="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><a href="nächste-schritte-in-r-bunte-bilder-und-mehr.html#pakete-installieren-und-laden"><i class="fa fa-check"></i><b>2.3</b> Pakete installieren und laden</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><a href="nächste-schritte-in-r-bunte-bilder-und-mehr.html#ein-kurzer-ausflug-ins-tidyverse"><i class="fa fa-check"></i><b>2.3.1</b> Ein kurzer Ausflug ins Tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="nächste-schritte-in-r-bunte-bilder-und-mehr.html"><a href="nächste-schritte-in-r-bunte-bilder-und-mehr.html#grafiken-mit-ggplot2"><i class="fa fa-check"></i><b>2.4</b> Grafiken mit ggplot2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html"><i class="fa fa-check"></i><b>3</b> Deskriptive Statistik in R</a>
<ul>
<li class="chapter" data-level="3.1" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#lernziele-2"><i class="fa fa-check"></i><b>3.1</b> Lernziele</a></li>
<li class="chapter" data-level="3.2" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#deskriptive-statistiken-mit-basis-r"><i class="fa fa-check"></i><b>3.2</b> Deskriptive Statistiken mit Basis R</a></li>
<li class="chapter" data-level="3.3" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#deskriptive-statistiken-im-tidyverse"><i class="fa fa-check"></i><b>3.3</b> Deskriptive Statistiken im Tidyverse</a></li>
<li class="chapter" data-level="3.4" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#deskriptive-statistiken-mit-anderen-paketen"><i class="fa fa-check"></i><b>3.4</b> Deskriptive Statistiken mit anderen Paketen</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#psych"><i class="fa fa-check"></i><b>3.4.1</b> Psych</a></li>
<li class="chapter" data-level="3.4.2" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#summarytools"><i class="fa fa-check"></i><b>3.4.2</b> Summarytools</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="deskriptive-statistik-in-r.html"><a href="deskriptive-statistik-in-r.html#mehr-bunte-bilder"><i class="fa fa-check"></i><b>3.5</b> Mehr bunte Bilder</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tests-in-r.html"><a href="tests-in-r.html"><i class="fa fa-check"></i><b>4</b> Theoretisch ja, praktisch auch! Tests in R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="tests-in-r.html"><a href="tests-in-r.html#lernziele-3"><i class="fa fa-check"></i><b>4.1</b> Lernziele</a></li>
<li class="chapter" data-level="4.2" data-path="tests-in-r.html"><a href="tests-in-r.html#normalverteilung-prüfen"><i class="fa fa-check"></i><b>4.2</b> Normalverteilung prüfen</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="tests-in-r.html"><a href="tests-in-r.html#ein-kurzer-ausflug-in-ergebnisobjekte"><i class="fa fa-check"></i><b>4.2.1</b> Ein kurzer Ausflug in Ergebnisobjekte</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="tests-in-r.html"><a href="tests-in-r.html#t-test-und-wilcoxon-test"><i class="fa fa-check"></i><b>4.3</b> T-Test und Wilcoxon-Test</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="tests-in-r.html"><a href="tests-in-r.html#formulas-in-r"><i class="fa fa-check"></i><b>4.3.1</b> Ein kurzer Ausflug in Formeln</a></li>
<li class="chapter" data-level="4.3.2" data-path="tests-in-r.html"><a href="tests-in-r.html#ein-kurzer-ausflug-in-funktionen"><i class="fa fa-check"></i><b>4.3.2</b> Ein kurzer Ausflug in Funktionen</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tests-in-r.html"><a href="tests-in-r.html#anova"><i class="fa fa-check"></i><b>4.4</b> ANOVA</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="tests-in-r.html"><a href="tests-in-r.html#broom-return-objects"><i class="fa fa-check"></i><b>4.4.1</b> Ein zweiter kurzer Ausfulg in Ergebnisobjekte</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="diverse-tipps-tricks-für-r.html"><a href="diverse-tipps-tricks-für-r.html"><i class="fa fa-check"></i><b>5</b> Diverse Tipps &amp; Tricks für R</a>
<ul>
<li class="chapter" data-level="5.1" data-path="diverse-tipps-tricks-für-r.html"><a href="diverse-tipps-tricks-für-r.html#lernziele-4"><i class="fa fa-check"></i><b>5.1</b> Lernziele</a></li>
<li class="chapter" data-level="5.2" data-path="diverse-tipps-tricks-für-r.html"><a href="diverse-tipps-tricks-für-r.html#nachvollziehbare-analysen-und-rmarkdown"><i class="fa fa-check"></i><b>5.2</b> Nachvollziehbare Analysen und Rmarkdown</a></li>
<li class="chapter" data-level="5.3" data-path="diverse-tipps-tricks-für-r.html"><a href="diverse-tipps-tricks-für-r.html#styleguide"><i class="fa fa-check"></i><b>5.3</b> Styleguide</a></li>
<li class="chapter" data-level="5.4" data-path="diverse-tipps-tricks-für-r.html"><a href="diverse-tipps-tricks-für-r.html#cheatsheets"><i class="fa fa-check"></i><b>5.4</b> Cheatsheets</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html"><i class="fa fa-check"></i><b>6</b> See one, do one, teach one! Machine Learning in R</a>
<ul>
<li class="chapter" data-level="6.1" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#lernziele-5"><i class="fa fa-check"></i><b>6.1</b> Lernziele</a></li>
<li class="chapter" data-level="6.2" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#das-iris-dataset"><i class="fa fa-check"></i><b>6.2</b> Das Iris Dataset</a></li>
<li class="chapter" data-level="6.3" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#explorative-datenvisualisierung"><i class="fa fa-check"></i><b>6.3</b> Explorative Datenvisualisierung</a></li>
<li class="chapter" data-level="6.4" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#lin-regression"><i class="fa fa-check"></i><b>6.4</b> Lineare Regression</a></li>
<li class="chapter" data-level="6.5" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#log-regression"><i class="fa fa-check"></i><b>6.5</b> Logistische Regression</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#roc-analysis"><i class="fa fa-check"></i><b>6.5.1</b> Ein kurzer Ausflug in ROC-Analysen</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#ml-preprocessing"><i class="fa fa-check"></i><b>6.6</b> Datenaufbereitung für Machine Learning</a></li>
<li class="chapter" data-level="6.7" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#support-vector-machine"><i class="fa fa-check"></i><b>6.7</b> Support Vector Machine</a></li>
<li class="chapter" data-level="6.8" data-path="see-one-do-one-teach-one-machine-learning-in-r.html"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#weitere-informationen-zu-machine-learning-in-r"><i class="fa fa-check"></i><b>6.8</b> Weitere Informationen zu Machine Learning in R</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html"><i class="fa fa-check"></i><b>7</b> Bilddaten, Datenbilder: Radiomics-Analysen in R</a>
<ul>
<li class="chapter" data-level="7.1" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#radiomics-howto"><i class="fa fa-check"></i><b>7.1</b> Lernziele</a></li>
<li class="chapter" data-level="7.2" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#daten-einlesen-1"><i class="fa fa-check"></i><b>7.2</b> Daten einlesen</a></li>
<li class="chapter" data-level="7.3" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#interreader-variabilität"><i class="fa fa-check"></i><b>7.3</b> Interreader Variabilität</a></li>
<li class="chapter" data-level="7.4" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#normalisierung"><i class="fa fa-check"></i><b>7.4</b> Normalisierung</a></li>
<li class="chapter" data-level="7.5" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#radiomics-boruta"><i class="fa fa-check"></i><b>7.5</b> Feature Reduction</a></li>
<li class="chapter" data-level="7.6" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#korrelationsanalyse"><i class="fa fa-check"></i><b>7.6</b> Korrelationsanalyse</a></li>
<li class="chapter" data-level="7.7" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#fitten-und-testen-des-modells"><i class="fa fa-check"></i><b>7.7</b> Fitten und Testen des Modells</a></li>
<li class="chapter" data-level="7.8" data-path="bilddaten-datenbilder-radiomics-analysen-in-r.html"><a href="bilddaten-datenbilder-radiomics-analysen-in-r.html#das-ende.-vielen-dank"><i class="fa fa-check"></i><b>7.8</b> Das Ende. Vielen Dank!</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Erstellt mit bookdown</a></li>
<li><a href="https://github.com/DRGagit/go-for-it" target="blank">Quelltext zum Buch bei GitHub</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">DRG/AGIT - Go for IT</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="see-one-do-one-teach-one-machine-learning-in-r" class="section level1" number="6">
<h1><span class="header-section-number">6</span> See one, do one, teach one! Machine Learning in R</h1>
<p>Nachdem wir uns nun bereits in deskriptive Statistiken und statistische Tests eingearbeitet haben, können wir einen Schritt weiter gehen und kommen zu dem Thema, das aktuell mehr denn je in aller Munde ist - <a href="https://de.wikipedia.org/wiki/Maschinelles_Lernen">Maschinelles Lernen bzw. Machine Learning</a>. In seinen einfacheren Ausprägungen ist maschinelles Lernen nichts anderes als die Erarbeitung eines statistischen Modells, welches dann wiederum auf neue Daten angewandt werden kann, um bspw. Vorhersagen zu treffen.</p>
<div class="figure">
<img src="assets/img/circles_of_ai.png" alt="" />
<p class="caption">Künstliche Intelligenz, Maschinelles Lernen und Neuronale Netze</p>
</div>
<p>Heute werden die Begriffe “Künstliche Intelligenz”, “Maschinelles Lernen” und “Neuronale Netzwerke” teils synonym verwandt. Korrekterweise kann man jedoch sagen, dass die neuronalen Netze ledigliche ein Teilgebiet des maschinellen Lernens sind, das wiederum ein Teil von dem bezeichnet was unter künstlicher Intelligenz verstanden wird. Im folgenden werden wir einige einfachere Algorithmen kennenlernen und in R ausprobiern. Wer danach noch Hunger auf mehr Machine Learning Algorithmen und deren Anwendung in R hat, dem sei die Webseite <a href="https://blog.datasciencedojo.com/machine-learning-algorithms/">101 Machine Learning Algorithms</a> ans Herz gelegt.</p>
<div id="lernziele-5" class="section level2" number="6.1">
<h2><span class="header-section-number">6.1</span> Lernziele</h2>
<ol style="list-style-type: decimal">
<li>Verschiedene Machine Learning Algorithmen in R nutzen</li>
<li>Daten in Training- und Testdaten unterteilen</li>
<li>Trainierte Modelle auf neue Daten anwenden</li>
<li>Klassifikationsgüte berechnen</li>
</ol>
</div>
<div id="das-iris-dataset" class="section level2" number="6.2">
<h2><span class="header-section-number">6.2</span> Das Iris Dataset</h2>
<p>In vielen Beipsielen wird online auf das sogenannte <a href="https://en.wikipedia.org/wiki/Iris_flower_data_set">Iris Dataset</a> Bezug genommen. Der Datensatz hat deshalb einige Berühmtheit erlangt, der Einfachheit halber verwenden wir ihn deshalb auch für dieses Webinar.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb147-1"></a><span class="kw">data</span>(<span class="st">&quot;iris&quot;</span>)</span>
<span id="cb147-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb147-2"></a><span class="kw">str</span>(iris)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<p>In dem Datensatz enthalten sind Beobachtungen zu 150 verschiedenen Schwertlilien enthalten, jede Beobachtung enthält Angaben zu Länge und Breite der Kelch- und Kronblätter sowie zur Zugehörigkeit zu einer von drei Schwertlilienarten. Die übliche Aufgabe ist es dann anhand dieses Datensatzes einen Algorithmus zu trainieren, der aus den Angaben zur Länge und Breite der Kelch- und Kronblätter Vorhersagen über die Artzugehörigkeit trifft.</p>
</div>
<div id="explorative-datenvisualisierung" class="section level2" number="6.3">
<h2><span class="header-section-number">6.3</span> Explorative Datenvisualisierung</h2>
<p>Ein guter Anfang ist meist sich einen visuellen Überblick über die Daten zu verschaffen. Man könnte beispielsweise die Verteilung der Messwerte als gruppierte Punktwolken darstellen.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb149-1"></a>iris <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb149-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb149-2"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>Species, <span class="dt">names_to =</span> <span class="st">&quot;variable&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb149-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb149-3"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Species, <span class="dt">y =</span> value, <span class="dt">color =</span> Species)) <span class="op">+</span></span>
<span id="cb149-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb149-4"></a><span class="st">    </span><span class="kw">geom_jitter</span>() <span class="op">+</span></span>
<span id="cb149-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb149-5"></a><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="kw">vars</span>(variable))</span></code></pre></div>
<p><img src="go_for_it_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p>Wie man sieht, müsste es möglich sein anhand der Daten die Artzugehörigkeit abzuschätzen. Rein visuell könnte man vermuten, dass sich dafür insbesondere die Länge der Kronblätter (<code>Petal-Length</code>) eignen müsste.</p>
</div>
<div id="lin-regression" class="section level2" number="6.4">
<h2><span class="header-section-number">6.4</span> Lineare Regression</h2>
<p>Einer der einfachsten Machine Learning Algorithmen, die <a href="https://de.wikipedia.org/wiki/Lineare_Regression">Lineare Regression</a> eignet sich zwar nicht zur Vorhersage eines kategorialen Variable, wie sie die Artzugehörigkeit ist, sollte aber hier trotzdem nicht unerwähnt bleiben. Üblicherweise versucht eine lineare Regression einen kontinuierlichen Zahlenwert für eine abhängige Variable aus einer oder mehreren unabhängigen Variablen zu berechnen. In unserem Fall könnten wir beispielsweise versuchen die Breite der Kronblätter (<code>Petal.Width</code>) aus den übrigen Variablen abzuschätzen.</p>
<p>Hierzu nutzen wir die Funktion <code>lm()</code>. Erster Parameter dieser Funktion ist eine Formel, wie wir sie bereits im Kapitel zu den statistischen Tests benutzt haben (Abschnitt <a href="tests-in-r.html#formulas-in-r">4.3.1</a>). In Formeln kann der Punkt <code>.</code> genutzt werden, um alle Variablen (bzw. Spalten) außer der links der Tilde <code>~</code> angegebenen zu referenzieren. Der zweite Parameter der Funktion ist das Dataframe, das genutzt werden soll. Da es hier keinen Sinn machen würde die Art einzuschließen, nutzen wir innerhalb der <code>lm()</code>-Funktion ein <code>select()</code>, um die Variable <code>Species</code> auszuschließen.</p>
<div class="sourceCode" id="cb150"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb150-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb150-1"></a>fit &lt;-<span class="st"> </span><span class="kw">lm</span>(<span class="dt">formula =</span> Petal.Width <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">select</span>(<span class="op">-</span>Species))</span>
<span id="cb150-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb150-2"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Petal.Width ~ ., data = iris %&gt;% select(-Species))
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.60959 -0.10134 -0.01089  0.09825  0.60685 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  -0.24031    0.17837  -1.347     0.18    
## Sepal.Length -0.20727    0.04751  -4.363 2.41e-05 ***
## Sepal.Width   0.22283    0.04894   4.553 1.10e-05 ***
## Petal.Length  0.52408    0.02449  21.399  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.192 on 146 degrees of freedom
## Multiple R-squared:  0.9379, Adjusted R-squared:  0.9366 
## F-statistic: 734.4 on 3 and 146 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Die Ausgabe ist auf den ersten Blick nicht besonders eingängig, zeigt aber im Wesentlichen schon, dass signifikante Zusammenhänge zwischen Kronblattbreite und allen anderen Variablen existieren.</p>
<p>Natürlich können auch die Ergebnisobjekte von Machine Learning Algorithmen für die weitere Nutzung mit Tidyverse-Paketen aufbereitet werden (siehe Abschnitt <a href="tests-in-r.html#broom-return-objects">4.4.1</a>).</p>
<div class="sourceCode" id="cb152"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb152-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb152-1"></a><span class="kw">library</span>(broom)</span>
<span id="cb152-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb152-2"></a><span class="kw">tidy</span>(fit)</span></code></pre></div>
<pre><code>## # A tibble: 4 x 5
##   term         estimate std.error statistic  p.value
##   &lt;chr&gt;           &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)    -0.240    0.178      -1.35 1.80e- 1
## 2 Sepal.Length   -0.207    0.0475     -4.36 2.41e- 5
## 3 Sepal.Width     0.223    0.0489      4.55 1.10e- 5
## 4 Petal.Length    0.524    0.0245     21.4  7.33e-47</code></pre>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-1"></a>fit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-2"></a><span class="st">  </span><span class="kw">tidy</span>(<span class="dt">conf.int =</span> <span class="ot">TRUE</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-3"></a><span class="st">  </span><span class="kw">filter</span>(term <span class="op">!=</span><span class="st"> &quot;(Intercept)&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-4"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">p.value.chr =</span> <span class="kw">format.pval</span>(p.value, <span class="dt">digits =</span> <span class="dv">2</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb154-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-5"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> estimate, <span class="dt">y =</span> <span class="kw">fct_reorder</span>(term, estimate))) <span class="op">+</span></span>
<span id="cb154-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-6"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb154-7"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-7"></a><span class="st">    </span><span class="kw">geom_errorbar</span>(<span class="kw">aes</span>(<span class="dt">xmin =</span> conf.low, <span class="dt">xmax =</span> conf.high), <span class="dt">width =</span> <span class="fl">0.15</span>) <span class="op">+</span></span>
<span id="cb154-8"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-8"></a><span class="st">    </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb154-9"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-9"></a><span class="st">    </span><span class="kw">geom_text</span>(<span class="kw">aes</span>(<span class="dt">label =</span> <span class="kw">paste</span>(<span class="st">&quot;p-value =&quot;</span>, p.value.chr)), <span class="dt">nudge_y =</span> <span class="fl">0.2</span>) <span class="op">+</span></span>
<span id="cb154-10"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-10"></a><span class="st">    </span><span class="kw">scale_x_continuous</span>(<span class="dt">limits =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.8</span>, <span class="fl">0.8</span>)) <span class="op">+</span></span>
<span id="cb154-11"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-11"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb154-12"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-12"></a>         <span class="dt">x =</span> <span class="st">&quot;Estimate&quot;</span>,</span>
<span id="cb154-13"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb154-13"></a>         <span class="dt">title =</span> <span class="st">&quot;Linear regression coefficients for Petal.Width&quot;</span>)</span></code></pre></div>
<p><img src="go_for_it_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
</div>
<div id="log-regression" class="section level2" number="6.5">
<h2><span class="header-section-number">6.5</span> Logistische Regression</h2>
<p>Einer der einfachtsten Machine Learning Algorithmen zur Vorhersage einer binären Entscheidung (wie bspw. benigne vs. maligne) ist die <a href="https://de.wikipedia.org/wiki/Logistische_Regression">Logistische Regression</a>. Das Vorgehen in R ist hierbei weitestgehend gleich zu dem bei der linearen Regression, nur dass wir in diesem Fall eben als abhängige Variable eine Variable nehmen müssen, die entweder als <code>Character</code> oder als <code>Factor</code> vorliegt und nur zwei Ausprägungen hat.</p>
<p>Im Iris-Datensatz könnten wir also beispeilsweise versuchen anhand von Blattlängen und -breiten zwischen den Arten <code>virginica</code> und <code>versicolor</code> zu unterscheiden. Dazu nutzen wir die Funktion <code>glm()</code> und geben dieser als Parameter <code>family = "binomial</code> mit.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-1"></a><span class="co"># Erstellen einer Teilmenge des Datensatzes mit nur zwei Spezies</span></span>
<span id="cb155-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-2"></a>iris_binominal &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span></span>
<span id="cb155-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-3"></a><span class="st">  </span><span class="kw">filter</span>(Species <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;virginica&quot;</span>, <span class="st">&quot;versicolor&quot;</span>)) <span class="op">%&gt;%</span></span>
<span id="cb155-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-4"></a><span class="st">  </span><span class="co"># da die Variable Species weiterhin als Factor mit drei Level</span></span>
<span id="cb155-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-5"></a><span class="st">  </span><span class="co"># angelegt wäre, nutzen wir die droplevels()-Funktion, um</span></span>
<span id="cb155-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-6"></a><span class="st">  </span><span class="co"># Fehler zu vermeiden.</span></span>
<span id="cb155-7"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-7"></a><span class="st">  </span><span class="kw">droplevels</span>()</span>
<span id="cb155-8"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-8"></a></span>
<span id="cb155-9"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-9"></a><span class="co"># family = &quot;binomial&quot; gibt hier an, dass nur eine binäre Entscheidung zu treffen ist</span></span>
<span id="cb155-10"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-10"></a>fit &lt;-<span class="st"> </span><span class="kw">glm</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris_binominal, <span class="dt">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb155-11"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb155-11"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## glm(formula = Species ~ ., family = &quot;binomial&quot;, data = iris_binominal)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -2.01105  -0.00541  -0.00001   0.00677   1.78065  
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)  
## (Intercept)   -42.638     25.707  -1.659   0.0972 .
## Sepal.Length   -2.465      2.394  -1.030   0.3032  
## Sepal.Width    -6.681      4.480  -1.491   0.1359  
## Petal.Length    9.429      4.737   1.991   0.0465 *
## Petal.Width    18.286      9.743   1.877   0.0605 .
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 138.629  on 99  degrees of freedom
## Residual deviance:  11.899  on 95  degrees of freedom
## AIC: 21.899
## 
## Number of Fisher Scoring iterations: 10</code></pre>
<p>In diesem konkreten Beispiel erscheint es so, dass lediglich die Kronblattlänge (<code>Petal.Length</code>) signifikant mit der Artzugehörigkeit zusammenhängt. In einem “echten” Projekt könnte man jetzt versuchen das Modell zu optimieren und nicht signifikante Faktoren entfernen, für unsere Zwecke arbeiten wir aber jetzt mit diesem (sicher nicht idealen) Modell weiter.</p>
<p>Wir können nun das in der Variablen <code>fit</code> gespeicherte Modell mithilfe der Funktion <code>predict()</code> nutzen, und uns die Vorhersagewerte des Modells zu ausgeben. Mit einigen praktischen Befehlen können wir die Vorhersagen auch gleich als neue Spalte dem ursprünglichen Dataframe hinzufügen.</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-1"></a><span class="co"># wir nutzen hier die add_column()-Funktion aus dem tidyverse</span></span>
<span id="cb157-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-2"></a><span class="co"># und die predict()-Funktion um Werte mithilfe eines Modells</span></span>
<span id="cb157-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-3"></a><span class="co"># zu berechnen</span></span>
<span id="cb157-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-4"></a>iris_binominal_predictions &lt;-<span class="st"> </span>iris_binominal <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb157-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-5"></a><span class="st">  </span><span class="kw">add_column</span>(<span class="dt">prediction_value =</span> <span class="kw">predict</span>(fit))</span>
<span id="cb157-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-6"></a></span>
<span id="cb157-7"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-7"></a><span class="co"># ein Blick in die ersten Zeilen der Daten</span></span>
<span id="cb157-8"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb157-8"></a><span class="kw">head</span>(iris_binominal_predictions)</span></code></pre></div>
<pre><code>##   Sepal.Length Sepal.Width Petal.Length Petal.Width    Species prediction_value
## 1          7.0         3.2          4.7         1.4 versicolor       -11.354482
## 2          6.4         3.2          4.5         1.5 versicolor        -9.932613
## 3          6.9         3.1          4.9         1.5 versicolor        -6.725380
## 4          5.5         2.3          4.0         1.3 versicolor       -10.073036
## 5          6.5         2.8          4.6         1.5 versicolor        -6.563842
## 6          5.7         2.8          4.5         1.3 versicolor        -9.191831</code></pre>
<p>Wie man sieht, gibt das Modell der logistischen Regression uns einen numerieschen Wert (in unserem Fall in der Spalte <code>prediction_value</code>) zurück, der in gewisser Weise aber die Zugehörigkeit zu der jeweiligen Klasse wiederspiegelt. Diese Daten könnten wir nun für eine einfache Visualisierung der Klassifikationsgenauigkeit nutzen.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-1"></a>iris_binominal_predictions <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb159-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">y =</span> prediction_value, <span class="dt">x =</span> Species, <span class="dt">color =</span> Species)) <span class="op">+</span></span>
<span id="cb159-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-3"></a><span class="st">    </span><span class="kw">geom_jitter</span>() <span class="op">+</span></span>
<span id="cb159-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-4"></a><span class="st">    </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">linetype =</span> <span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb159-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-5"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Spezies&quot;</span>,</span>
<span id="cb159-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-6"></a>         <span class="dt">y =</span> <span class="st">&quot;Ausgabewert der logistischen Regression&quot;</span>,</span>
<span id="cb159-7"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-7"></a>         <span class="dt">color =</span> <span class="st">&quot;&quot;</span>) <span class="op">+</span></span>
<span id="cb159-8"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb159-8"></a><span class="st">    </span><span class="kw">theme</span>(<span class="dt">legend.position =</span> <span class="st">&quot;none&quot;</span>)</span></code></pre></div>
<p><img src="go_for_it_files/figure-html/unnamed-chunk-64-1.png" width="672" />
Wie wir aus der Grafik unschwer erkennen, scheinen positive Werte für die Ausgabe der logistischen Regression eher für Schwertlilien der Art <code>virginica</code> zu sprechen, negative Werte für die Art <code>versicolor</code>. Nur in je einem Fall liegt dieses Modell für beide Arten liegt das Modell falsch.</p>
<div id="roc-analysis" class="section level3" number="6.5.1">
<h3><span class="header-section-number">6.5.1</span> Ein kurzer Ausflug in ROC-Analysen</h3>
<p>Ohne zu sehr darauf eingehen zu wollen, an dieser Stelle ein kurzer Exkurs zu <a href="https://de.wikipedia.org/wiki/ROC-Kurve">ROC-Analysen</a>. In einer ROC-Kurve wird sozusagen jede Kombination von Sensitivität und Spezifität aufgetragen, die sich in Abhängigkeit von der Variation eines Parameters (in unserem Fall also bspw. der Ausgabewert der logistischen Regression) ergibt. Je näher die Fläche unterhalb der ROC-Kurve am Wert 1 ist, desto besser die diagnostische oder prädiktive Performance eines Modells.</p>
<p>In R können ROC-Kurven und dazugehörige Berechnungen sehr einfach mit dem Paket <code>pROC</code> vorgenommen werden. Im Folgenden nehmen wir das Dataframe mit den ergänzten Vorhersagewerten und teilen der Funktion <code>roc()</code> als ersten Parameter den wahren Wert (hier also <code>Species</code>) und als zweiten Parameter den vorhersagenden Wert (hier also <code>prediction_value</code>) mit.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb160-1"></a><span class="kw">library</span>(pROC)</span>
<span id="cb160-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb160-2"></a>iris_binominal_predictions <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb160-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb160-3"></a><span class="st">  </span><span class="kw">roc</span>(Species, prediction_value)</span></code></pre></div>
<pre><code>## 
## Call:
## roc.data.frame(data = ., response = Species, predictor = prediction_value)
## 
## Data: prediction_value in 50 controls (Species versicolor) &lt; 50 cases (Species virginica).
## Area under the curve: 0.9972</code></pre>
<p>Wie wir erwartet hätte funktioniert unser Modell sehr gut und erreicht eine AUC von 0.99.</p>
<p>Noch eingängiger wäre nun auch eine entsprechende grafische Darstellung der Kurve. Erfreulicherweise enthält das Paket <code>pROC</code> auch hierfür Funktionen, insbesondere die Funktion <code>ggroc()</code>, die direkt eine in <code>ggplot</code> weiter modifizierbare Grafik erzeugt.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb162-1"></a>iris_binominal_predictions <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb162-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb162-2"></a><span class="st">  </span><span class="kw">roc</span>(Species, prediction_value) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb162-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb162-3"></a><span class="st">  </span><span class="kw">ggroc</span>(<span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb162-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb162-4"></a><span class="st">    </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">xend =</span> <span class="dv">0</span>, <span class="dt">y =</span> <span class="dv">0</span>, <span class="dt">yend =</span> <span class="dv">1</span>),</span>
<span id="cb162-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb162-5"></a>                 <span class="dt">color=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb162-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb162-6"></a><span class="st">    </span><span class="kw">coord_fixed</span>()</span></code></pre></div>
<p><img src="go_for_it_files/figure-html/unnamed-chunk-66-1.png" width="672" /></p>
<p>Wollen wir diese Grafik dann noch bspw. um weitere wichtige Informationen ergänzen, können wir auch ganz das einfach erreichen.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-1"></a><span class="co"># zunächst speichern wir unsere ROC-Analyse in einer Variablen</span></span>
<span id="cb163-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-2"></a>roc_result &lt;-<span class="st"> </span>iris_binominal_predictions <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb163-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-3"></a><span class="st">  </span><span class="kw">roc</span>(Species, prediction_value)</span>
<span id="cb163-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-4"></a></span>
<span id="cb163-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-5"></a><span class="co"># AUC und optimaler threshold werden berechnet und in Variablen gespeichert</span></span>
<span id="cb163-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-6"></a>roc_auc &lt;-<span class="st"> </span><span class="kw">auc</span>(roc_result)</span>
<span id="cb163-7"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-7"></a>roc_optimal_point &lt;-<span class="st"> </span><span class="kw">coords</span>(roc_result, <span class="st">&quot;best&quot;</span>, <span class="dt">transpose =</span> <span class="ot">FALSE</span>)</span>
<span id="cb163-8"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-8"></a></span>
<span id="cb163-9"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-9"></a><span class="co"># ROC-Kurve mit Anmerkungen</span></span>
<span id="cb163-10"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-10"></a>roc_result <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb163-11"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-11"></a><span class="st">  </span><span class="kw">ggroc</span>(<span class="dt">color =</span> <span class="st">&quot;steelblue&quot;</span>, <span class="dt">size =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb163-12"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-12"></a><span class="st">    </span><span class="kw">geom_segment</span>(<span class="kw">aes</span>(<span class="dt">x =</span> <span class="dv">1</span>, <span class="dt">xend =</span> <span class="dv">0</span>, <span class="dt">y =</span> <span class="dv">0</span>, <span class="dt">yend =</span> <span class="dv">1</span>),</span>
<span id="cb163-13"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-13"></a>                 <span class="dt">color=</span><span class="st">&quot;grey&quot;</span>, <span class="dt">linetype=</span><span class="st">&quot;dashed&quot;</span>) <span class="op">+</span></span>
<span id="cb163-14"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-14"></a><span class="st">    </span><span class="kw">coord_fixed</span>() <span class="op">+</span></span>
<span id="cb163-15"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-15"></a><span class="st">    </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x =</span> <span class="fl">0.05</span>, <span class="dt">y =</span> <span class="fl">0.1</span>, <span class="dt">label =</span> <span class="kw">paste</span>(<span class="st">&quot;AUC =&quot;</span>, roc_auc), <span class="dt">hjust =</span> <span class="dv">1</span>) <span class="op">+</span></span>
<span id="cb163-16"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-16"></a><span class="st">    </span><span class="kw">geom_text</span>(<span class="dt">data =</span> roc_optimal_point,</span>
<span id="cb163-17"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-17"></a>              <span class="kw">aes</span>(<span class="dt">x =</span> specificity, <span class="dt">y =</span> sensitivity, <span class="dt">label =</span> <span class="kw">paste</span>(<span class="st">&quot;Best operating point =&quot;</span>, <span class="kw">round</span>(threshold, <span class="dv">2</span>),</span>
<span id="cb163-18"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-18"></a>                                                                  <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Sensitivity:&quot;</span>, <span class="kw">round</span>(sensitivity, <span class="dv">2</span>),</span>
<span id="cb163-19"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-19"></a>                                                                  <span class="st">&quot;</span><span class="ch">\n</span><span class="st">Specificity:&quot;</span>, <span class="kw">round</span>(specificity, <span class="dv">2</span>)</span>
<span id="cb163-20"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-20"></a>                                                                  )),</span>
<span id="cb163-21"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-21"></a>              <span class="dt">hjust =</span> <span class="dv">0</span>, <span class="dt">vjust =</span> <span class="dv">1</span>,</span>
<span id="cb163-22"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-22"></a>              <span class="dt">nudge_x =</span> <span class="fl">0.02</span>, <span class="dt">nudge_y =</span> <span class="fl">-0.02</span>,</span>
<span id="cb163-23"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-23"></a>              <span class="dt">size =</span> <span class="dv">3</span>) <span class="op">+</span></span>
<span id="cb163-24"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb163-24"></a><span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(<span class="dt">x =</span> roc_optimal_point<span class="op">$</span>specificity, <span class="dt">y =</span> roc_optimal_point<span class="op">$</span>sensitivity), <span class="dt">color =</span> <span class="st">&quot;orange&quot;</span>, <span class="dt">shape =</span> <span class="dv">4</span>, <span class="dt">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<p><img src="go_for_it_files/figure-html/unnamed-chunk-67-1.png" width="672" /></p>
</div>
</div>
<div id="ml-preprocessing" class="section level2" number="6.6">
<h2><span class="header-section-number">6.6</span> Datenaufbereitung für Machine Learning</h2>
<p>Für die Anwendung “komplizierterer” Machine Learning Algorithmen sollte man sich an einige wichtige Regel halten. Ohne, dass wir hier alle Details bedenken können, sind zwei wichtige Schritte sicherlich die <a href="https://en.wikipedia.org/wiki/Normalization_(statistics)">Normalisierung der Daten</a> und die Aufteilung in Trainings- und Testdaten.</p>
<p>Für beide Arbeitsschritte können wir Funktionen aus dem Paket <code>caret</code> benutzen. Für die Normalisierung der Daten legen wir zunächst mit der Funktion <code>preProcess()</code> ein Objekt an, das die relevanten Informationen enthält, dieses wiederum wenden wir dann mit der schon bekannten Funktion <code>predict()</code> an.</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-1"></a><span class="kw">library</span>(caret)</span>
<span id="cb164-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-2"></a></span>
<span id="cb164-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-3"></a>preprocess_object &lt;-<span class="st"> </span><span class="kw">preProcess</span>(iris, <span class="dt">method=</span><span class="kw">c</span>(<span class="st">&quot;range&quot;</span>))</span>
<span id="cb164-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-4"></a></span>
<span id="cb164-5"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-5"></a>iris_normalized &lt;-<span class="st"> </span><span class="kw">predict</span>(preprocess_object, iris)</span>
<span id="cb164-6"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-6"></a></span>
<span id="cb164-7"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-7"></a>iris_normalized <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb164-8"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-8"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="op">-</span>Species, <span class="dt">names_to =</span> <span class="st">&quot;variable&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb164-9"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Species, <span class="dt">y =</span> value, <span class="dt">color =</span> Species)) <span class="op">+</span></span>
<span id="cb164-10"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-10"></a><span class="st">    </span><span class="kw">geom_jitter</span>() <span class="op">+</span></span>
<span id="cb164-11"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-11"></a><span class="st">    </span><span class="kw">facet_wrap</span>(<span class="kw">vars</span>(variable)) <span class="op">+</span></span>
<span id="cb164-12"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb164-12"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;normalized value&quot;</span>)</span></code></pre></div>
<p><img src="go_for_it_files/figure-html/unnamed-chunk-68-1.png" width="672" /></p>
<p>Man erkennt, dass nun alle Werte auf einen Bereich zwischen 0 und 1 abgebildet wurden, was bspw. die Vergleichbarkeit (auch visuell, vgl. Abschnitt <a href="see-one-do-one-teach-one-machine-learning-in-r.html#explorative-datenvisualisierung">6.3</a>) verbessern kann.</p>
<p>Im nächsten Schritt wollen wir die Daten aufteilen, sodass wir einen Datensatz erhalten, den wir zum Training unseres Algorithmus nutzen, und einen Datensatz, den wir zum Testen bzw. Validieren unseres Modells nutzen. Dabei sollte gewährleistet werden, dass in beiden Gruppen alle Werte annähernd ähnlich verteilt sind, die Zuordnung aber möglichst trotzdem zufällig stattfindet. Auch hier können wir uns einer Funktion des Pakets <code>caret</code> bedienen, in dem Fall die Funktion <code>createDataPartition()</code>. Dieser Funktion müssen wir als Parameter noch die Spalte mitgeben, die unsere vorherzusagende Variable enthält (in unserem Fall also <code>iris$Species</code>), welcher Prozentsatz der Daten dem Training zugeordnet werden soll (z.B.: 80%) und ob wir ein <code>list</code>-Objekt erhalten wollen (wenn wir nur <em>eine</em> Aufteilung machen wollen, sollte man hier <code>FALSE</code> wählen). Da die Funktion uns nur die Position der Zeilen des Dataframes, die zur Trainingsgruppe gehören sollen, gibt, ist es praktischer diese in einer Variablen zu speichern, die wir dann nutzen, um aus dem ursprünglichen Dataframe die entsprechenden Zeilen zu selektieren bzw. zu entfernen.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb165-1"></a>training_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(iris<span class="op">$</span>Species, <span class="dt">p =</span> <span class="fl">.8</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</span>
<span id="cb165-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb165-2"></a></span>
<span id="cb165-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb165-3"></a>iris_training &lt;-<span class="st"> </span>iris[training_index,]</span>
<span id="cb165-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb165-4"></a>iris_testing  &lt;-<span class="st"> </span>iris[<span class="op">-</span>training_index,]</span></code></pre></div>
<p>Um das Ergebnis zu kontrollieren, können wir bspw. die bekannten Funktionen zur Erstellung deskriptiver Statistiken nutzen (bspw. die Funktionen aus dem Paket <code>summarytools</code>, siehe auch Abschnitt <a href="deskriptive-statistik-in-r.html#summarytools">3.4.2</a>).</p>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb166-1"></a><span class="co"># Da der Output recht lang ist, führen wir hier nur die Befehle auf.</span></span>
<span id="cb166-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb166-2"></a><span class="kw">library</span>(summarytools)</span>
<span id="cb166-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb166-3"></a><span class="kw">dfSummary</span>(iris_training)</span>
<span id="cb166-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb166-4"></a><span class="kw">dfSummary</span>(iris_testing)</span></code></pre></div>
<p>Sobald wir unsere Daten entsprechend aufgeteilt haben, können wir anfangen unsere Modelle zu trainieren.</p>
</div>
<div id="support-vector-machine" class="section level2" number="6.7">
<h2><span class="header-section-number">6.7</span> Support Vector Machine</h2>
<p>Ein gern und häufig verwendeter, etwas komplexerer Machine Learning Algorithmus zur Klassifikation auch mehrerer Gruppen ist die <a href="https://de.wikipedia.org/wiki/Support_Vector_Machine">Support Vector Machine</a>. Der Algorithmus versucht hierbei möglichst gute Trennungen zwischen den Klassen (auch mehreren) in einem sogenannten Vektorraum zu finden.</p>
<p>In R gibt es mehrere Pakete, die Support Vector Machines zur Verfügung stellen, ein Beispiel wäre das Paket <code>e1071</code>. Das Vorgehen ist dem bei der logistischen Regression (siehe <a href="see-one-do-one-teach-one-machine-learning-in-r.html#log-regression">6.5</a>) sehr ähnlich. Der Funktion <code>svm()</code> übergeben wir auch in diesem Falle eine Formel und den entsprechenden Datensatz. Hier ist es allerdings wichtig nur den Trainingsdatensatz zu verwenden.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb167-1"></a><span class="kw">library</span>(e1071)</span>
<span id="cb167-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb167-2"></a></span>
<span id="cb167-3"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb167-3"></a>fit &lt;-<span class="st"> </span><span class="kw">svm</span>(Species <span class="op">~</span><span class="st"> </span>., <span class="dt">data =</span> iris_training)</span>
<span id="cb167-4"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb167-4"></a><span class="kw">summary</span>(fit)</span></code></pre></div>
<pre><code>## 
## Call:
## svm(formula = Species ~ ., data = iris_training)
## 
## 
## Parameters:
##    SVM-Type:  C-classification 
##  SVM-Kernel:  radial 
##        cost:  1 
## 
## Number of Support Vectors:  47
## 
##  ( 8 20 19 )
## 
## 
## Number of Classes:  3 
## 
## Levels: 
##  setosa versicolor virginica</code></pre>
<p>Ein solches Modell erschließt sich entsprechend nicht ganz so intuitiv wie bspw. eine linieare Regression (<a href="see-one-do-one-teach-one-machine-learning-in-r.html#lin-regression">6.4</a>). Für die meisten unserer Anwendungen muss dies aber kein Nachteil sein, es sollte aber bei solchen Algorithmen in besonderem Maße darauf geachtet werden, dass letztlich nur die Ergebnisse in dem Testdatensatz bedeutend sind. Gute Ergebnisse in den Trainingsdaten können auch lediglich Ausdruck eines sogenannten <a href="https://de.wikipedia.org/wiki/Überanpassung">Overfittings</a> sein und sind nicht immer auf die Testdaten übertragbar.</p>
<p>In einem zweiten Schritt wenden wir, wie auch schon bei den Regressionen, daher nun das trainierte Modell auf neue Daten an - in diesem Fall den Testdatensatz, der nicht Teil des Trainingsprozesses war.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb169-1"></a>iris_test &lt;-<span class="st"> </span>iris_testing <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb169-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb169-2"></a><span class="st">  </span><span class="kw">add_column</span>(<span class="dt">prediction =</span> <span class="kw">predict</span>(fit, iris_testing))</span></code></pre></div>
<p>Zur Bewertung der diagnostischen Genauigkeit des Modells sind eine Reihe Maßzahlen üblich. Erfreulicherweise enthält das o.g. Paket <code>caret</code> auch einige praktische Funktionen, um diese einfach berechnen zu lassen. Die Funktion <code>confusionMatrix()</code> benötigt dazu als Parameter eine Kreuztabelle, die wir in R wiederum mithilfe der Funktion <code>table()</code> erstellen können.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb170-1"></a><span class="kw">table</span>(iris_test<span class="op">$</span>Species, iris_test<span class="op">$</span>prediction) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb170-2"><a href="see-one-do-one-teach-one-machine-learning-in-r.html#cb170-2"></a><span class="st">  </span><span class="kw">confusionMatrix</span>()</span></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             
##              setosa versicolor virginica
##   setosa         10          0         0
##   versicolor      0         10         0
##   virginica       0          0        10
## 
## Overall Statistics
##                                      
##                Accuracy : 1          
##                  95% CI : (0.8843, 1)
##     No Information Rate : 0.3333     
##     P-Value [Acc &gt; NIR] : 4.857e-15  
##                                      
##                   Kappa : 1          
##                                      
##  Mcnemar&#39;s Test P-Value : NA         
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 1.0000            1.0000           1.0000
## Specificity                 1.0000            1.0000           1.0000
## Pos Pred Value              1.0000            1.0000           1.0000
## Neg Pred Value              1.0000            1.0000           1.0000
## Prevalence                  0.3333            0.3333           0.3333
## Detection Rate              0.3333            0.3333           0.3333
## Detection Prevalence        0.3333            0.3333           0.3333
## Balanced Accuracy           1.0000            1.0000           1.0000</code></pre>
<p>Die Funktion <code>confusionMatrix()</code> gibt erfreulicherweise auch gleich die Kreuztabelle mit aus. Dabei entsprechen die Zeilen dem “wahren” Label oder Wert und die Spalten der Vorhersage des Algorithmus. Wir sehen also nun, dass sich der Algorithmus nur in zwei Fällen im Testdatensatz vertan hat (beide Male gab der Algorithmus Art <code>versicolor</code> aus, obwohl es sich um Schwertlilien der Art <code>virginica</code> handelte).</p>
</div>
<div id="weitere-informationen-zu-machine-learning-in-r" class="section level2" number="6.8">
<h2><span class="header-section-number">6.8</span> Weitere Informationen zu Machine Learning in R</h2>
<p>Natürlich können wir an dieser Stelle nicht alle Machine Learning Algorithmen behandeln, die man in R nutzen kann. Eine tolle Zusammenstellung vieler Algorithmen, inkl. Tutorials in R, findet man auf der Webseite <a href="https://blog.datasciencedojo.com/machine-learning-algorithms/">DataScienceDojo</a>. Wie man schnell sieht sind die hier verwendeten nur ein kleiner Ausschnitt. Trotzdem, alleine mit diesen vier Paketen hat man viele der typischerweise in der Radiologie angewandten Techniken zur Verfügung:</p>
<ul>
<li><a href="https://github.com/tidymodels/broom"><code>broom</code></a> enthält etliche praktische Funktionen, um mit Modellen zu interagieren</li>
<li><a href="http://caret.r-forge.r-project.org"><code>caret</code></a> bietet Funktionen zum Präprozessieren und Aufteilen von Daten</li>
<li><a href="https://www.rdocumentation.org/packages/e1071/versions/1.7-3"><code>e1071</code></a> stellt Funktionen für Support Vector Machines zur Verfügung</li>
<li><a href="https://web.expasy.org/pROC/"><code>pROC</code></a> ermöglicht ROC-Analysen inkl. deren graphische Darstelung</li>
</ul>

</div>
</div>
<div id="disqus_thread"></div>
<script>
(function() { // DON'T EDIT BELOW THIS LINE
var d = document, s = d.createElement('script');
s.src = 'https://go-for-it.disqus.com/embed.js';
s.setAttribute('data-timestamp', +new Date());
(d.head || d.body).appendChild(s);
})();
</script>
<noscript>Please enable JavaScript to view the
<a href="https://disqus.com/?ref_noscript">
  comments powered by Disqus.</a></noscript>
            </section>

          </div>
        </div>
      </div>
<a href="diverse-tipps-tricks-für-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bilddaten-datenbilder-radiomics-analysen-in-r.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

</body>

</html>
