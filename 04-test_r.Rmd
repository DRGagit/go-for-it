# Theoretisch ja, praktisch auch! Tests in R {#tests-in-r}

Üblicherweise geht es nach den deskriptiven Statistiken in den meisten Fällen ans Eingemachte - die [statistischen Tests](https://de.wikipedia.org/wiki/Statistischer_Test). Nehmen wir an, in zwei Gruppen beobachten wir unterschiedliche Mittelwerte. Eine mögliche Erklärung könnte sein, dass der bloße Zufall hier Unterschiede erscheinen lässt, wo in Wirklichkeit keine sind. Eine andere Möglichkeit wäre dann, dass in der Tat Unterschiede zwischen den Gruppen bestehen, und diese nicht alleine dem Zufall zu schulden sind.

Die gesamten theoretischen Grundlagen hier zu wiederholen würde sicher den Rahmen sprengen, insofern beschränken wir uns im Folgenden mit der Durchführung verschiedener statistischer Tests in R. Welcher Test wann der geeignete ist, ist manchmal nicht leicht zu erkennen. Für eine erste grobe Einschätzung kann aber die folgende Tabelle hilfreich sein.

![Mögliche statistische Tests in Abhängigkeit der Variablen. (Tabelle ursprünglich aus Wikipedia unter Creative Commons Lizenz)](./assets/img/stat_tests.png)

## Lernziele

- Daten auf Normalverteilung prüfen (Shapiro-Test)
- Einfache statistische Tests rechnen (T-Test, Wilcoxon-Test)
- Effektstärke berechnen und eigene Funktionen schreiben
- ANOVA durchführen

## Normalverteilung prüfen

Wie aus obiger Tabelle ersichtlich ist, kann es mitunter zur Auswahl des korrekten statistischen Tests wichtig sein zunächst zu prüfen, ob die Werte einer Variablen normalverteilt sind. Natürlich können wir versuchen visuell abzuschätzen, ob dies der Fall ist. Für ein fiktives Beispiel wären wir zudem interessiert, die Normalverteilung für einen Wert innerhalb verschiedener Gruppen zu untersuchen. Eine schnelle deskriptive Statistik bzw. Visualisierung könnte wie folgt aussehen.

Wir nutzen hier die `skew()`-Funktion aus dem `psych` Paket, um die [Schiefe](https://de.wikipedia.org/wiki/Schiefe_(Statistik)) der Verteilung zu erhalten (bei einer Normalverteilung nahe 0, bei positiven Werten ist der Ausläufer nach rechts länger, bei negativen Werten der Ausläufer nach links).

```{r}
library(psych)

daten %>%
  group_by(untersuchung) %>%
  summarise(schiefe_dlp = skew(dlp))

daten %>%
  ggplot(aes(x = dlp, fill = untersuchung)) +
    geom_density() +
    facet_wrap(vars(untersuchung)) +
    labs(x = "DLP [mGy*cm]",
         y = "",
         fill = "Untersuchungsbezeichnung") +
    theme_bw()
```

Wir sehen hier bereits, dass die DLP-Werte für Untersuchungen des Kopfes und bei Traumaspiralen vermutlich normalverteilt sind. Doch um wirklich sicher zu gehen, sollte ein entsprechender statistischer Test verwendet werden. Für diese Frage bietet sich der [Shapiro-Wilk-Test](https://de.wikipedia.org/wiki/Shapiro-Wilk-Test) an.

Der Shapiro-Wilk-Test nimmt als sog. Nullhypothese an, dass die Daten normalverteilt sind. Ein kleiner p-Wert zeigt in diesem Fall dann entsprechen an, dass die Alternativhypothese anzunehmen ist, also dass die Daten nicht normalverteilt sind. Erfreulicherweise findet sich für die meisten statistischen Tests in R eine entsprechend benannte Funktion. Um also bspw. die DLP-Werte im gesamten Datensatz auf Normalverteilung zu untersuchen, können wir einfach die Funktion `shapiro.test()` nutzen.

```{r}
shapiro.test(daten$dlp)
```

In diesem Fall zeigt also der p-Wert < 2,2 x 10<sup>-16</sup> an, dass die Alternativhypothese angenommen werden sollte - die DLP-Werte im Gesamtdatensatz also nicht normalverteilt sind.

### Ein kurzer Ausflug in Ergebnisobjekte

In vielen Fällen sind die Ausgaben solcher statistischen Tests etwas unintuitiv formatiert und die einzelnen Werte weiterzuverwenden erscheint zunächst schwierig. Es lohnt daher an dieser Stelle ein kurzer Ausflug, denn wir können durchaus auf Einzelteile der Ausgabe direkt zugreifen. Um einen etwas tieferen Einblick zu erhalten, speichern wir zunächst das Ergebnis der `shapiro.test()` Funktion in einer Variablen und schauen uns die Struktur der Variablen an.

```{r}
shapiro.ergebnis <- shapiro.test(daten$dlp)
str(shapiro.ergebnis)
```

Wie man erkennen kann, handelt es sich um eine Liste von Werten, die einfach—wenn sie nicht in einer Variablen gespeichert sind—gemeinsam auf der Konsole ausgegeben werden. Das Dollarzeichen `$` in der Ausgabe der `str()` Funktion zeigt hier aber bereits an, dass wir auch einzelne Teile des Ergebnisses direkt referenzieren können, ähnlich den Spalten eines Dataframes.

```{r}
shapiro.ergebnis$p.value

shapiro.ergebnis$p.value < 0.05
```

Wären wir also bspw. in obigem fiktiven Beispiel daran interessiert die Normalverteilung innerhalb der Subgruppen zu prüfen, könnten wir in Tidyverse-Syntax eine Verkettung von Befehlen schreiben, an deren Ende eine ansprechend formatierte Tabelle stünde, die in einer Spalte auch gleich prüft, ob der p-Wert unterhalb des Signifikanzniveau von 0.05 liegt.

```{r}
daten %>%
  group_by(untersuchung) %>%
  summarise(shapiro_p.wert = shapiro.test(dlp)$p.value) %>%
  mutate(signifikant_0.05 = shapiro_p.wert < 0.05)
```

Wir sehen also, dass—entgegen der ursprünglichen Annahme—auch in den Gruppen, die rein visuell und deskriptiv normalverteilt erschienen (Kopf und Traumaspirale), in Wirklichkeit keine Normalverteilung vorliegt.

## T-Test und Wilcoxon-Test

Nachdem nun die Daten auf Normalverteilung geprüft wurden, können wir mit dem entsprechenden statistischen Test untersuchen, ob zwischen einzelnen Gruppen ein signifikanter Unterschied in der Verteilung der Werte für eine Variable existiert. In unserem Falle wäre, da die Daten nicht normalverteilt sind, der [Wilcoxon-Mann-Whitney-Test](https://de.wikipedia.org/wiki/Wilcoxon-Mann-Whitney-Test) die richtige Wahl. Ähnlich wie für den Shapiro-Wilk-Test `shapiro.test()` existiert in diesem Falle die Funktion `wilcoxon.test()`. Die Funktion erwartet als Parameter entweder zwei Vektoren mit Zahlenwerten (oder ein Dataframe und eine sogenannte Formel, aber dazu später). Für ein einfaches Beispiel wollen wir den Vergleich der DLP-Werte von Thorax-Untersuchungen mit denen von Abdomen-Untersuchungen untersuchen. Hierzu ziehen wir uns zunächst die entsprechenden Werte aus dem Dataframe heraus und speichern sie in separaten Variablen, anschließend können diese Vektoren der Funktion `wilcoxon.test()` übergeben werden. Im Übrigen geht R bei T-Test und Wilcoxon-Test davon aus, dass es sich um unverbundene Stichproben handelt. Sicherheitshalber sollte man sich aber angewöhnen, dies auch explizit mithilfe des Parameters `paired = FALSE` anzugeben.

```{r}
# erst die Funktion pull() extrahiert aus dem Dataframe einen einfachen Vektor
dlp.abdomen <- daten %>% filter(untersuchung == "Abdomen") %>% pull(dlp)
dlp.thorax  <- daten %>% filter(untersuchung == "Thorax")  %>% pull(dlp)

wilcox.test(dlp.abdomen, dlp.thorax, paired = FALSE)
```

Wie erwartet, zeigt hier der p-Wert < 2,2 x 10<sup>-16</sup> an, dass die DLP-Werte von Thorax-Untersuchungen und Abdomen-Untersuchungen signifikant verschieden sind.

Genau so einfach ließe sich entsprechend auch ein T-Test `t.test()` rechnen, der zwar in diesem Falle vielleicht nicht optimal wäre, weil wie bereits besprochen keine Normalverteilung der Werte vorliegt, aber das ignorieren wir einmal.

```{r}
t.test(dlp.abdomen, dlp.thorax, paired = FALSE)
```

### Ein kurzer Ausflug in Formeln {#formulas-in-r}

Mit Formeln werden in R nicht übliche Formeln in der Art `f(x) = mx + b` bezeichnet, sondern bei der Definition von statistischen Tests oder Modellen ein Ausdruck, der beschreibt welche Zielvariable von welchen Einflussvariablen abhängen soll. Eine Formel in R besteht immer aus einer Tilde `~` und einem oder mehreren Ausdrücken, die jeweils rechts (RHS = right hand side) bzw. links (LHS = left hand side) der Tilde `~` stehen. Die Zielvariable steht dabei links (LHS) und die möglichen Einflussvariablen rechts (RHS).

Wollten wir also beispielsweise ausdrücken, dass wir das DLP in Abhängigkeit der Untersuchungsbeschreibung auf statistische Signifikanz untersuchen wollen würden, könnten wir das folgendermaßen ausdrücken: `dlp ~ untersuchung`. Wollten wir also in unserem Beispiel die beiden Gruppen Thorax und Abdomen vergleichen, könnten wir den Ausdruck `daten %>% filter(untersuchung %in% c("Abdomen", "Thorax"))` nutzen, um ein Dataframe zu erzeugen, das nur diese beiden Gruppen enthält. Bei dem Aufruf der Funktion `t.test()` müssten wir dieses Dataframe als Parameter `data = ` übergeben und als ersten Parameter die oben genannte Formel `dlp ~ untersuchung`.

```{r}
# auch hier hilft eine Schreibweise mit Zeilenumbrüchen nicht den Überblick zu verlieren
t.test(
  dlp ~ untersuchung,
  data = daten %>% filter(untersuchung %in% c("Abdomen", "Thorax")),
  paired = FALSE
  )
```

Das mag zunächst etwas kompliziert wirken. Aber solche Schreibweisen haben den Vorteil, dass nicht für jeden Test neue Variablen definiert werden müssen, was bei langen und komplizierten Auswertungen schonmal dazu führen kann, dass man den Überblick verliert. Für einfache statistische Tests ist die Formelschreibweise nicht unbedingt nötig, und beide Herangehensweisen liefern identische Ergebnisse. Im späteren Kapitel zu Machine Learning werden wir allerdings um die Verwendung dieser Formelschreibweise nicht herum kommen.

### Ein kurzer Ausflug in Funktionen

Im Live-Webinar hatten wir darüber gesprochen, dass bspw. beim T-Test neben dem p-Wert auch die sog. [Effektstärke](https://de.wikipedia.org/wiki/Effektstärke) relevant sein kann. Zwar existiert für R beispielsweise das Paket [`effsize`](https://cran.r-project.org/web/packages/effsize/index.html), das Funktionen enthält um die Effektstärke zu berechnen, aber gelegentlich kommt vielleicht man an einen Punkt, wo auf die Schnelle kein Paket zu finden ist, dass genau die Funktion enthält, die man sucht. Für solche Fälle bietet R die Möglichkeit, eigene Funktionen zu definieren, die der Vollständigkeit hier genannt werden soll, obwohl diese spezielle Funktionalität für den Anfang vielleicht etwas komplex ist.

Für ein kurzes Beispiel wollen wir einen Spezialfall betrachten, in dem für unverbundene Stichproben gleicher Gruppengröße die Effektstärke anhand von T-Statistik und df-Wert des T-Testes brechnet werden kann. Wir wollen dabei das Ergebnisobjekt der Funktion `t.test()` nehmen und direkt die Werte für T-Statistik und df extrahiert und sodann die Effektstärke berechnet werden kann.

Eine Funktion kann einfach mithilfe der Funktion `function()` definiert werden, und in einer Variable gespeichert werden, die genutzt werden kann, um die Funktion aufzurufen. Innerhalb der runden Klammern `()` von `function()` können Parameter definiert werden, die dann innerhalb der Funktion verfügbar sind. Beim Aufruf kann auch an selbst definierte Formeln mithilfe des Verkettungsoperators `%>%` ein Parameter übergeben werden. Die Möglichkeiten, die sich hierdurch ergeben sind schier endlos...

```{r}
meine_cohens_d_funktion <- function(ergebnis_t.test) {
  # Die Funktion unname() ist hier für eine schönere Ausgabe am Ende
  # der Funktion nötig. Kann aber auch ignoriert werden.
  t_statistik <- ergebnis_t.test$statistic %>% unname()
  df_wert     <- ergebnis_t.test$parameter %>% unname()

  # Formel für Cohens d
  # siehe auch https://www.uccs.edu/lbecker/
  2 * t_statistik / sqrt(df_wert)
}

t.test(
  dlp ~ untersuchung,
  data = daten %>% filter(untersuchung %in% c("Abdomen", "Thorax")),
  paired = FALSE
  ) %>% meine_cohens_d_funktion()
```

## ANOVA

Was aber wenn wir nun nicht nur zwei Gruppen auf signifikante Unterschiede hin untersuchen wollen, sondern gleich mehrere? Der Gedanke einfach bspw. mehrere T-Tests hintereinander zu machen, läge natürlich nahe. Aber dabei ergäbe sich ein zentrales Problem: Wenn wir für unsere Test ein [Signifikanzniveau](https://de.wikipedia.org/wiki/Statistische_Signifikanz#Irrtumswahrscheinlichkeit_und_Signifikanzniveau) von 0.05 ansetzen, die Wahrscheinlichkeit keinen Typ I Fehler zu machen also bei 95% liegt, würde sich bei einem Vergleich von nur drei Gruppen schon eine Wahrscheinlichkeit von knapp 14% ergeben mindestens eine Nullhypothese falsch abzulehnen.

Für genau solche Fälle eignen sich sogenannte [Varianzanalysen](https://de.wikipedia.org/wiki/Varianzanalyse) (im Englischen auch als ANOVA = _analysis of variance_ bezeichnet). Diese Verfahren testen im Grunde genommen die Nullhypothese, dass die Mittelwerte aller Gruppen gleich sind. In R kann eine solche Varianzanalyse sehr einfach mit der Funktion `aov()` durchgeführt werden, wobei der p-Wert hier nur ausgegeben wird, wenn man sich das Ergebnisobjekt genauer ansieht.

```{r}
aov(dlp ~ untersuchung, data = daten) %>% summary()
```

In diesem Fall sehen wir als, dass wir unsere Nullhypothese verwerfen können, d.h. für das DLP gibt es in Abhängigkeit von der Untersuchungsart signifikante Unterschiede der Mittelwerte zwischen den Gruppen. Dieses Ergebnis ist für sich genommen natürlich wenig hilfreich, denn das wirklich interessante wäre nun zu wissen, welche Gruppen sich auf welche Art unterscheiden. Hierfür können sogenannte [post-hoc Tests](https://de.wikipedia.org/wiki/Post-hoc-Test) durchgeführt werden, die die Ergebnisse der Varianzanalyse weiter untersuchen und automatisch für das [multiple Testen](https://de.wikipedia.org/wiki/Alphafehler-Kumulierung) korrigieren. Ein Beispiel für einen solchen post-hoc Test ist der Tukey-Test, für den R die Funktion `TukeyHSD()` enthält.

```{r}
aov(dlp ~ untersuchung, data = daten) %>% TukeyHSD()
```

Das Ergebnis zeigt uns nun, dass außer für die Vergleiche Gesicht/Becken, Thorax/Becken und Thorax/Gesicht, jeweils signifikante Unterschiede der DLP-Mittelwerte bestehen (die p-Werte sind in der letzten Spalte zu finden). Zudem wird die mittlere Differenz sowie das 95%-Konfidenzintervall der Unterschiede mit ausgegeben.

### Ein zweiter kurzer Ausfulg in Ergebnisobjekte {#broom-return-objects}

Gerade solche Ausgaben, wie die der `TukeyHSD()` Funktion sind manchmal etwas unübersichtlich, obwohl sie ja eigentlich sogar eine Tabelle mit ausgeben. Diese Tabelle aber wiederum weiter zu manipulieren, ist mit R Basisfunktionen kaum möglich. Erfreulicherweise gibt es auch hier aus dem Tidyverse einige praktische Helferfunktionen, die in dem Paket [`broom`](https://broom.tidyverse.org) enthalten sind. Insbesondere die Funktion `tidy()` hilft Ergebnistabellen statistischer Tests in saubere Dataframes zu überführen, mit denen dann wie gewohnt weitergearbeitet werden kann.

```{r}
library(broom)

# zunächst speichern wir das Ergebnis des Tukey-Tests, wobei natürlich auch eine
# direkte Verkettung zur tidy()-Funktion, usw. möglich wäre
tukey.ergebnis <- aov(dlp ~ untersuchung, data = daten) %>% TukeyHSD()

# Tukey Ergebnisse im tidy-Format
# (sieht in der Ausgabe hier online nicht so sehr anders aus,
# in RStudio ist der Unterschied deutlicher)
tukey.ergebnis %>% 
  tidy()

# sind die Tukey Ergebnisse einmal in ein sauberes Dataframe überführt, können wir
# alle Tidyverse-Funktionen in gewohnter Weise nutzen
# bspw. nur die signifkanten Ergebnisse anzeigen, nach Größe der mittleren Differenz
# sortiert, und das ganze dann graphisch aufbereitet
tukey.ergebnis %>% 
  tidy() %>% 
  filter(adj.p.value < 0.05) %>% 
  select(contrast, estimate, adj.p.value) %>% 
  ggplot(aes(x = fct_reorder(contrast, estimate), y = estimate, fill = adj.p.value)) +
    geom_col() +
    coord_flip()  +
    labs(x = "Vergleich",
         y = "Mittlere Differenz DLP",
         fill = "p-Wert") +
    theme_bw()
```

